{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dd1590-1dd7-4380-93b7-4491789eb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport sentiment_utils\n",
    "%aimport mytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff51efb6-9982-433e-b9b7-73a3ad88d354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:          3.11.3 (main, Apr  7 2023, 20:13:31) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "scikit-learn:    1.2.2\n",
      "Gensim:          4.3.1\n",
      "PyTorch:         2.0.1\n",
      "Transformers:    4.30.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_lr_finder import LRFinder\n",
    "import transformers\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
    "                          DataCollatorWithPadding, TrainingArguments, Trainer)\n",
    "\n",
    "\n",
    "print('python:'.ljust(16), sys.version.split('\\n')[0])\n",
    "print('scikit-learn:'.ljust(16), sklearn.__version__)\n",
    "print('Gensim:'.ljust(16), gensim.__version__)\n",
    "print('PyTorch:'.ljust(16), torch.__version__)\n",
    "print('Transformers:'.ljust(16), transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d3a80-84d9-4a1a-996a-bc30784d09db",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5038b4-d83c-4bde-a230-0ca7538d5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {DEVICE} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1d08d-6b4f-4979-8ff5-b397c84c0383",
   "metadata": {},
   "source": [
    "# Hyperparameters & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6420d850-2109-4edc-937f-246d5d0312cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "VOCAB_SIZE = 50000\n",
    "SVD_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15  # select from: 2**n - 1 = [1, 3, 7, 15, ...]\n",
    "SCHEDULER_GAMMA = 0.7\n",
    "\n",
    "# Constants\n",
    "WORKING_PATH = './sentiment-data/'\n",
    "MODEL_PATH = '../app/models/'\n",
    "DATASET_NAME = 'tweet_eval'\n",
    "DATASET_CONF = 'sentiment'\n",
    "CLASSES = 3\n",
    "LABEL_MAP = {\n",
    "    0: 'negative',\n",
    "    1: 'neutral',\n",
    "    2: 'positive',\n",
    "}\n",
    "HUGGINGFACE_MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# Actions\n",
    "DO_LR_RANGE_TEST=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c5513-1785-4de5-a58b-797d6ddd243e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a433eb7-c8d0-44bf-a7d1-867166772870",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2147483647\n",
    "# random.seed(RANDOM_STATE)\n",
    "# np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a62e08-a57d-46f5-8d21-74df9a240575",
   "metadata": {},
   "source": [
    "# Load & show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc60f77-c4fe-459c-9a84-e2c674833aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (/Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dadeb0379041649cabe553e34e90a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12284\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(DATASET_NAME, DATASET_CONF)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb58da6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [{'filename': '/Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/tweet_eval-train.arrow'}],\n",
       " 'test': [{'filename': '/Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/tweet_eval-test.arrow'}],\n",
       " 'validation': [{'filename': '/Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/tweet_eval-validation.arrow'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cache_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cfef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'neutral', 'positive'], id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a608d6b-b412-4319-8576-02575aa5d512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"',\n",
       "  '\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"',\n",
       "  'Sorry bout the stream last night I crashed out but will be on tonight for sure. Then back to Minecraft in pc tomorrow night.',\n",
       "  \"Chase Headley's RBI double in the 8th inning off David Price snapped a Yankees streak of 33 consecutive scoreless innings against Blue Jays\",\n",
       "  '@user Alciato: Bee will invest 150 million in January, another 200 in the Summer and plans to bring Messi by 2017\"'],\n",
       " 'label': [2, 1, 1, 1, 2]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96a266-7271-4ae2-816c-a5bdf86037b3",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## TokTokTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c113720",
   "metadata": {},
   "source": [
    "Try tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3040eda8-5742-4c0d-b412-343ad7dd3fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "qt @user origin draft 7th book , remu lupin surviv battl hogwarts. #happybirthdayremuslupin\n",
      "\n",
      "\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"\n",
      "ben smith / smith ( concuss ) remain lineup thursday , curti #nhl #sj\n",
      "\n",
      "Sorry bout the stream last night I crashed out but will be on tonight for sure. Then back to Minecraft in pc tomorrow night.\n",
      "sorri bout stream last night crash tonight sure. back minecraft pc tomorrow night .\n",
      "\n",
      "Chase Headley's RBI double in the 8th inning off David Price snapped a Yankees streak of 33 consecutive scoreless innings against Blue Jays\n",
      "chase headley ' rbi doubl 8th inning david price snap yanke streak 33 consecut scoreless inning blue jay\n",
      "\n",
      "@user Alciato: Bee will invest 150 million in January, another 200 in the Summer and plans to bring Messi by 2017\"\n",
      "@user alciato : bee invest 150 million januari , anoth 200 summer plan bring messi 2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = sentiment_utils.Tokenizer()\n",
    "\n",
    "for text in dataset['train']['text'][:5]:\n",
    "    print(text)\n",
    "    print(tokenizer(text, return_str=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283f037-250c-4c24-b8e1-4a6fd5a4bfed",
   "metadata": {},
   "source": [
    "## RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53202f7",
   "metadata": {},
   "source": [
    "Try tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b53938-fca8-45ec-8e00-77e2f56ba46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_NAME)\n",
    "\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed5173ee-4af2-4dbb-87b8-e99ff4fd413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "<s>\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\" \"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"</s>\n",
      "['<s>', '\"', 'Q', 'T', 'Ġ@', 'user', 'ĠIn', 'Ġthe', 'Ġoriginal', 'Ġdraft', 'Ġof', 'Ġthe', 'Ġ7', 'th', 'Ġbook', ',', 'ĠRem', 'us', 'ĠLup', 'in', 'Ġsurvived', 'Ġthe', 'ĠBattle', 'Ġof', 'ĠHogwarts', '.', 'Ġ#', 'Happy', 'Birth', 'day', 'Rem', 'us', 'L', 'up', 'in', '\"', 'Ġ\"', 'Q', 'T', 'Ġ@', 'user', 'ĠIn', 'Ġthe', 'Ġoriginal', 'Ġdraft', 'Ġof', 'Ġthe', 'Ġ7', 'th', 'Ġbook', ',', 'ĠRem', 'us', 'ĠLup', 'in', 'Ġsurvived', 'Ġthe', 'ĠBattle', 'Ġof', 'ĠHogwarts', '.', 'Ġ#', 'Happy', 'Birth', 'day', 'Rem', 'us', 'L', 'up', 'in', '\"', '</s>']\n",
      "[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 23, 23, 23, 23, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 40, 41, 42, 43, 44, 45, 46, 47, 48, 48, 48, 48, 48, 48, 48, 48, 49, None]\n",
      "tensor([[    0,   113,  1864,   565,   787, 12105,    96,     5,  1461,  2479,\n",
      "             9,     5,   262,   212,  1040,     6,  8022,   687, 26110,   179,\n",
      "          5601,     5,  9846,     9, 42210,     4,   849, 21136, 44728,  1208,\n",
      "         31157,   687,   574,   658,   179,   113,    22,  1864,   565,   787,\n",
      "         12105,    96,     5,  1461,  2479,     9,     5,   262,   212,  1040,\n",
      "             6,  8022,   687, 26110,   179,  5601,     5,  9846,     9, 42210,\n",
      "             4,   849, 21136, 44728,  1208, 31157,   687,   574,   658,   179,\n",
      "           113,     2]])\n",
      "['\"', 'Q', 'T', 'Ġ@', 'user', 'ĠIn', 'Ġthe', 'Ġoriginal', 'Ġdraft', 'Ġof', 'Ġthe', 'Ġ7', 'th', 'Ġbook', ',', 'ĠRem', 'us', 'ĠLup', 'in', 'Ġsurvived', 'Ġthe', 'ĠBattle', 'Ġof', 'ĠHogwarts', '.', 'Ġ#', 'Happy', 'Birth', 'day', 'Rem', 'us', 'L', 'up', 'in', '\"', 'Ġ\"', 'Q', 'T', 'Ġ@', 'user', 'ĠIn', 'Ġthe', 'Ġoriginal', 'Ġdraft', 'Ġof', 'Ġthe', 'Ġ7', 'th', 'Ġbook', ',', 'ĠRem', 'us', 'ĠLup', 'in', 'Ġsurvived', 'Ġthe', 'ĠBattle', 'Ġof', 'ĠHogwarts', '.', 'Ġ#', 'Happy', 'Birth', 'day', 'Rem', 'us', 'L', 'up', 'in', '\"']\n",
      "\n",
      "\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"\n",
      "<s>\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\" \"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"</s>\n",
      "['<s>', '\"', 'Ben', 'ĠSmith', 'Ġ/', 'ĠSmith', 'Ġ(', 'con', 'cussion', ')', 'Ġremains', 'Ġout', 'Ġof', 'Ġthe', 'Ġlineup', 'ĠThursday', ',', 'ĠCurtis', 'Ġ#', 'N', 'HL', 'Ġ#', 'S', 'J', '\"', 'Ġ\"', 'Ben', 'ĠSmith', 'Ġ/', 'ĠSmith', 'Ġ(', 'con', 'cussion', ')', 'Ġremains', 'Ġout', 'Ġof', 'Ġthe', 'Ġlineup', 'ĠThursday', ',', 'ĠCurtis', 'Ġ#', 'N', 'HL', 'Ġ#', 'S', 'J', '\"', '</s>']\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 38, 39, 40, 40, 41, None]\n",
      "tensor([[    0,   113, 17521,  1259,  1589,  1259,    36,  3865, 33825,    43,\n",
      "          1189,    66,     9,     5,  4451,   296,     6, 11292,   849,   487,\n",
      "          8064,   849,   104,   863,   113,    22, 17521,  1259,  1589,  1259,\n",
      "            36,  3865, 33825,    43,  1189,    66,     9,     5,  4451,   296,\n",
      "             6, 11292,   849,   487,  8064,   849,   104,   863,   113,     2]])\n",
      "['\"', 'Ben', 'ĠSmith', 'Ġ/', 'ĠSmith', 'Ġ(', 'con', 'cussion', ')', 'Ġremains', 'Ġout', 'Ġof', 'Ġthe', 'Ġlineup', 'ĠThursday', ',', 'ĠCurtis', 'Ġ#', 'N', 'HL', 'Ġ#', 'S', 'J', '\"', 'Ġ\"', 'Ben', 'ĠSmith', 'Ġ/', 'ĠSmith', 'Ġ(', 'con', 'cussion', ')', 'Ġremains', 'Ġout', 'Ġof', 'Ġthe', 'Ġlineup', 'ĠThursday', ',', 'ĠCurtis', 'Ġ#', 'N', 'HL', 'Ġ#', 'S', 'J', '\"']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in dataset['train']['text'][:2]:\n",
    "    print(text)\n",
    "    \n",
    "    preprocessed_text = sentiment_utils.preprocess_text(text)\n",
    "    model_input = tokenizer(\n",
    "        preprocessed_text,\n",
    "#         padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt',\n",
    "#         return_offsets_mapping=True,\n",
    "    )\n",
    "    print(tokenizer.decode(model_input['input_ids'][0]))\n",
    "    print(model_input.tokens())\n",
    "    print(model_input.word_ids())\n",
    "    print(model_input['input_ids'])\n",
    "#     print(model_input['offset_mapping'])\n",
    "    \n",
    "    tokens = tokenizer.tokenize(preprocessed_text)\n",
    "    print(tokens)\n",
    "    print()\n",
    "    \n",
    "# type(model_input).mro()\n",
    "# model_input.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34661994",
   "metadata": {},
   "source": [
    "Tokenize the whole dataset to prepare it for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980647cb-223f-4652-b443-7ff76cb51afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-e69e5419e9b6a115.arrow\n",
      "Loading cached processed dataset at /Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-460ef6407e274887.arrow\n",
      "Loading cached processed dataset at /Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-a4d147f31b1fa3d9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 ms, sys: 5.36 ms, total: 46.7 ms\n",
      "Wall time: 46.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 45615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 12284\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def tokenize_function(examples):\n",
    "    preprocessed_text = sentiment_utils.preprocess_text(examples['text'])\n",
    "    return tokenizer(preprocessed_text)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_dataset = tokenized_dataset.remove_columns('text')\n",
    "# tokenized_dataset = tokenized_dataset.rename_column('label', 'labels')\n",
    "# tokenized_dataset = tokenized_dataset.with_format('torch')\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9472fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMetrics:\n",
    "    def __init__(self):\n",
    "        self.metric = evaluate.load(DATASET_NAME, DATASET_CONF)\n",
    "        \n",
    "    def __call__(self, eval_preds):\n",
    "        logits, labels = eval_preds\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return self.metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60e6760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/admin/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/750 04:00 < 08:01, 1.04 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='629' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 629/1536 03:03 < 04:24, 3.43 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model,\n\u001b[1;32m      9\u001b[0m                   training_args,\n\u001b[1;32m     10\u001b[0m                   data_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                   tokenizer,\n\u001b[1;32m     14\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mComputeMetrics)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:2034\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2034\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:2300\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2298\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2300\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:3029\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3026\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3028\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3029\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3033\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3039\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:3210\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3207\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3209\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3210\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3211\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:3466\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3465\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3466\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3467\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/trainer.py:2767\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2766\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2767\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2769\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1216\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1228\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:411\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:347\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    330\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    338\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    339\u001b[0m         hidden_states,\n\u001b[1;32m    340\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m         output_attentions,\n\u001b[1;32m    346\u001b[0m     )\n\u001b[0;32m--> 347\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:298\u001b[0m, in \u001b[0;36mRobertaSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    296\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    297\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 298\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1494\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1495\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(HUGGINGFACE_MODEL_NAME)\n",
    "\n",
    "training_args = TrainingArguments(WORKING_PATH + 'training_data',\n",
    "                                  evaluation_strategy='epoch')\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(model,\n",
    "                  training_args,\n",
    "                  data_collator,\n",
    "                  tokenized_dataset['train'],\n",
    "                  tokenized_dataset['validation'],\n",
    "                  tokenizer,\n",
    "                  compute_metrics=ComputeMetrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29efae-6858-4dd6-98d4-7f0824f53130",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "## Document vectorizers\n",
    "### BOW, TF-IDF, Hashing BOW and their SVD variants\n",
    "Fit vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a363196-375b-4a06-a9c2-c648e0ce46f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance for SVD:\n",
      "BOW:         51.53 %\n",
      "Hashing BOW: 41.75 %\n",
      "TF-IDF:      16.51 %\n",
      "\n",
      "CPU times: user 1min 10s, sys: 7.23 s, total: 1min 17s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_vectorizers = True\n",
    "file_vectorizers = WORKING_PATH + 'document_vectorizers_' + str(VOCAB_SIZE) + '_' + str(SVD_SIZE) + '.pickle'\n",
    "\n",
    "# Load vectorizer if it already exists\n",
    "if os.path.isfile(file_vectorizers):\n",
    "    with open(file_vectorizers, 'rb') as f:\n",
    "        vectorizers = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = sentiment_utils.Tokenizer()\n",
    "\n",
    "    # Initialize vectorizers\n",
    "    vectorizers = {'toktok': {\n",
    "        'bow': CountVectorizer(lowercase=False,\n",
    "                               tokenizer=tokenizer,\n",
    "                               max_features=VOCAB_SIZE),\n",
    "        'hbow': HashingVectorizer(lowercase=False,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  n_features=VOCAB_SIZE),\n",
    "        'tfidf': TfidfTransformer(),\n",
    "        'bow_svd': TruncatedSVD(n_components=SVD_SIZE),\n",
    "        'hbow_svd': TruncatedSVD(n_components=SVD_SIZE),\n",
    "        'tfidf_svd': TruncatedSVD(n_components=SVD_SIZE),\n",
    "    }}\n",
    "    # Fit vectorizers and transform train data\n",
    "    bow_train_texts = vectorizers['toktok']['bow'].fit_transform(dataset['train']['text'])\n",
    "    hbow_train_texts = vectorizers['toktok']['hbow'].fit_transform(dataset['train']['text'])\n",
    "    tfidf_train_texts = vectorizers['toktok']['tfidf'].fit_transform(bow_train_texts)\n",
    "\n",
    "    # Fit SVD-truncated vectorizers\n",
    "    vectorizers['toktok']['bow_svd'].fit(bow_train_texts)\n",
    "    vectorizers['toktok']['hbow_svd'].fit(hbow_train_texts)\n",
    "    vectorizers['toktok']['tfidf_svd'].fit(tfidf_train_texts)\n",
    "    \n",
    "    # Save vectorizers\n",
    "    if save_vectorizers:\n",
    "        with open(file_vectorizers, 'wb') as f:\n",
    "            pickle.dump(vectorizers, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Print SVD explained variance\n",
    "print('Explained variance for SVD:')\n",
    "print('BOW:        ', round(vectorizers['toktok']['bow_svd'].explained_variance_ratio_.sum() * 100, 2), '%')\n",
    "print('Hashing BOW:', round(vectorizers['toktok']['hbow_svd'].explained_variance_ratio_.sum() * 100, 2), '%')\n",
    "print('TF-IDF:     ', round(vectorizers['toktok']['tfidf_svd'].explained_variance_ratio_.sum() * 100, 2), '%')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21281e38-f9d6-40b4-94db-fd66c1bf3165",
   "metadata": {},
   "source": [
    "Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aded4063-7e5f-4fe7-8689-54262cfc545b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full size data shapes:\n",
      "BOW:         (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "Hashing BOW: (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "TF-IDF:      (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "\n",
      "SVD-truncated data shapes:\n",
      "BOW:         (45615, 100) (2000, 100) (12284, 100)\n",
      "Hashing BOW: (45615, 100) (2000, 100) (12284, 100)\n",
      "TF-IDF:      (45615, 100) (2000, 100) (12284, 100)\n",
      "\n",
      "CPU times: user 14 s, sys: 88.2 ms, total: 14.1 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform_data = True\n",
    "save_data = True\n",
    "file_data = WORKING_PATH + 'document_data_' + str(VOCAB_SIZE) + '_' + str(SVD_SIZE) + '.pickle'\n",
    "\n",
    "if transform_data:\n",
    "    # Load transformed data if it already exists\n",
    "    if os.path.isfile(file_data):\n",
    "        with open(file_data, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        data = {'toktok': {\n",
    "            'bow': {\n",
    "                'train': vectorizers['toktok']['bow'].transform(dataset['train']['text']),\n",
    "                'valid': vectorizers['toktok']['bow'].transform(dataset['validation']['text']),\n",
    "                'test': vectorizers['toktok']['bow'].transform(dataset['test']['text']),\n",
    "            },\n",
    "            'hbow': {\n",
    "                'train': vectorizers['toktok']['hbow'].transform(dataset['train']['text']),\n",
    "                'valid': vectorizers['toktok']['hbow'].transform(dataset['validation']['text']),\n",
    "                'test': vectorizers['toktok']['hbow'].transform(dataset['test']['text']),\n",
    "            },\n",
    "        }}\n",
    "        \n",
    "        data['toktok']['tfidf'] = {\n",
    "            'train': vectorizers['toktok']['tfidf'].transform(data['toktok']['bow']['train']),\n",
    "            'valid': vectorizers['toktok']['tfidf'].transform(data['toktok']['bow']['valid']),\n",
    "            'test': vectorizers['toktok']['tfidf'].transform(data['toktok']['bow']['test']),\n",
    "        }\n",
    "\n",
    "        data['toktok']['bow_svd'] = {\n",
    "            'train': vectorizers['toktok']['bow_svd'].transform(data['toktok']['bow']['train']),\n",
    "            'valid': vectorizers['toktok']['bow_svd'].transform(data['toktok']['bow']['valid']),\n",
    "            'test': vectorizers['toktok']['bow_svd'].transform(data['toktok']['bow']['test']),\n",
    "        }\n",
    "\n",
    "        data['toktok']['hbow_svd'] = {\n",
    "            'train': vectorizers['toktok']['hbow_svd'].transform(data['toktok']['hbow']['train']),\n",
    "            'valid': vectorizers['toktok']['hbow_svd'].transform(data['toktok']['hbow']['valid']),\n",
    "            'test': vectorizers['toktok']['hbow_svd'].transform(data['toktok']['hbow']['test']),\n",
    "        }\n",
    "\n",
    "        data['toktok']['tfidf_svd'] = {\n",
    "            'train': vectorizers['toktok']['tfidf_svd'].transform(data['toktok']['tfidf']['train']),\n",
    "            'valid': vectorizers['toktok']['tfidf_svd'].transform(data['toktok']['tfidf']['valid']),\n",
    "            'test': vectorizers['toktok']['tfidf_svd'].transform(data['toktok']['tfidf']['test']),\n",
    "        }\n",
    "\n",
    "        # Save transformed data\n",
    "        if save_data:\n",
    "            with open(file_data, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Print shapes\n",
    "    print('Full size data shapes:')\n",
    "    print('BOW:        ',\n",
    "          data['toktok']['bow']['train'].shape,\n",
    "          data['toktok']['bow']['valid'].shape,\n",
    "          data['toktok']['bow']['test'].shape)\n",
    "    print('Hashing BOW:',\n",
    "          data['toktok']['hbow']['train'].shape,\n",
    "          data['toktok']['hbow']['valid'].shape,\n",
    "          data['toktok']['hbow']['test'].shape)\n",
    "    print('TF-IDF:     ',\n",
    "          data['toktok']['tfidf']['train'].shape,\n",
    "          data['toktok']['tfidf']['valid'].shape,\n",
    "          data['toktok']['tfidf']['test'].shape)\n",
    "    print()\n",
    "    print('SVD-truncated data shapes:')\n",
    "    print('BOW:        ',\n",
    "          data['toktok']['bow_svd']['train'].shape,\n",
    "          data['toktok']['bow_svd']['valid'].shape,\n",
    "          data['toktok']['bow_svd']['test'].shape)\n",
    "    print('Hashing BOW:',\n",
    "          data['toktok']['hbow_svd']['train'].shape,\n",
    "          data['toktok']['hbow_svd']['valid'].shape,\n",
    "          data['toktok']['hbow_svd']['test'].shape)\n",
    "    print('TF-IDF:     ',\n",
    "          data['toktok']['tfidf_svd']['train'].shape,\n",
    "          data['toktok']['tfidf_svd']['valid'].shape,\n",
    "          data['toktok']['tfidf_svd']['test'].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5a25c-6f83-44a3-ae64-45d4fa21f445",
   "metadata": {},
   "source": [
    "Form datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb61acdd-dda5-4f45-b0a7-516a24ce2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if isinstance(self.x[i], np.ndarray):\n",
    "            x = self.x[i]\n",
    "        else:\n",
    "            x = self.x[i].todense()\n",
    "        return x, self.y[i]\n",
    "\n",
    "\n",
    "datasets = {'toktok': {\n",
    "    'bow': {\n",
    "        'train': Doc2VecDataset(data['toktok']['bow']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['bow']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['bow']['test'], dataset['test']['label']),\n",
    "    },\n",
    "    'hbow': {\n",
    "        'train': Doc2VecDataset(data['toktok']['hbow']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['hbow']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['hbow']['test'], dataset['test']['label']),\n",
    "    },\n",
    "    'tfidf': {\n",
    "        'train': Doc2VecDataset(data['toktok']['tfidf']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['tfidf']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['tfidf']['test'], dataset['test']['label']),\n",
    "    },\n",
    "    'bow_svd': {\n",
    "        'train': Doc2VecDataset(data['toktok']['bow_svd']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['bow_svd']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['bow_svd']['test'], dataset['test']['label']),\n",
    "    },\n",
    "    'hbow_svd': {\n",
    "        'train': Doc2VecDataset(data['toktok']['hbow_svd']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['hbow_svd']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['hbow_svd']['test'], dataset['test']['label']),\n",
    "    },\n",
    "    'tfidf_svd': {\n",
    "        'train': Doc2VecDataset(data['toktok']['tfidf_svd']['train'], dataset['train']['label']),\n",
    "        'valid': Doc2VecDataset(data['toktok']['tfidf_svd']['valid'], dataset['validation']['label']),\n",
    "        'test': Doc2VecDataset(data['toktok']['tfidf_svd']['test'], dataset['test']['label']),\n",
    "    },\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe78e3-00ba-443a-84fc-b5e578ad7285",
   "metadata": {},
   "source": [
    "Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3c59491-350b-4cb4-8fe6-b73845eabcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples:   45615\n",
      "Validation examples: 2000\n",
      "Test examples:       12284\n",
      "\n",
      "Training batches:   713\n",
      "Validation batches: 32\n",
      "Test batches:       192\n",
      "\n",
      "Shape of X: torch.Size([64, 1, 50000]) torch.int64\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "\n",
      "Shape of X: torch.Size([64, 100]) torch.float64\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1555e-01,  1.6407e-01, -2.7625e-01, -2.4199e-02,  1.1401e-01,\n",
       "         3.1504e-02,  1.1226e+00, -2.4902e-01, -5.6359e-01,  3.2294e-01,\n",
       "         6.2872e-02,  2.8139e-01, -3.3960e-01,  3.8802e-02, -5.7210e-02,\n",
       "        -4.7027e-03,  3.7865e-02, -1.0003e-01,  4.3402e-02,  2.9222e-03,\n",
       "        -6.7827e-02,  1.5661e-03,  2.0842e-02,  1.6896e-02, -8.8386e-02,\n",
       "        -3.0166e-02, -5.1601e-02, -2.9432e-02, -1.3618e-03,  5.0311e-03,\n",
       "         1.8233e-03, -5.8659e-02, -3.2248e-02,  9.3290e-03,  1.9913e-02,\n",
       "        -2.9928e-02,  1.3025e-02, -3.0176e-02,  9.9205e-03,  7.6976e-03,\n",
       "        -4.1902e-02, -5.3152e-02,  1.2157e-02, -2.9063e-02,  4.9892e-02,\n",
       "         4.1866e-02, -4.7178e-02,  3.7598e-02, -4.4794e-02, -6.9791e-03,\n",
       "        -1.1249e-02,  5.5423e-02,  4.6279e-02,  1.0261e-02, -6.5526e-02,\n",
       "        -1.5512e-02, -2.3795e-02, -2.9470e-02, -1.9551e-02, -5.3367e-02,\n",
       "         4.8417e-02, -1.7730e-02,  1.0392e-01,  8.4523e-05,  7.8961e-02,\n",
       "         1.1607e-01, -8.6686e-02, -6.0226e-02, -7.4946e-02, -2.2558e-01,\n",
       "         1.4537e-01, -1.3754e-01, -1.4769e-01,  7.3627e-02, -1.5033e-01,\n",
       "         9.3529e-02,  4.4211e-02,  3.3540e-02,  1.2996e-01, -9.3171e-02,\n",
       "         8.0742e-02,  2.6368e-02, -1.9044e-01,  1.1518e-01, -2.2165e-02,\n",
       "         3.8818e-01,  1.8287e-01,  2.1045e-01,  4.4327e-01, -3.0083e-01,\n",
       "        -1.1786e-01,  8.5990e-02, -8.3996e-02, -1.0017e-01,  6.7826e-01,\n",
       "         4.5220e-01,  3.8801e-01, -6.2181e-02, -2.3829e-02,  1.8178e-01],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloaders = {'toktok': {\n",
    "    'bow': {\n",
    "        'train': DataLoader(datasets['toktok']['bow']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['bow']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['bow']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "    'hbow': {\n",
    "        'train': DataLoader(datasets['toktok']['hbow']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['hbow']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['hbow']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "    'tfidf': {\n",
    "        'train': DataLoader(datasets['toktok']['tfidf']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['tfidf']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['tfidf']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "    'bow_svd': {\n",
    "        'train': DataLoader(datasets['toktok']['bow_svd']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['bow_svd']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['bow_svd']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "    'hbow_svd': {\n",
    "        'train': DataLoader(datasets['toktok']['hbow_svd']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['hbow_svd']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['hbow_svd']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "    'tfidf_svd': {\n",
    "        'train': DataLoader(datasets['toktok']['tfidf_svd']['train'], batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'valid': DataLoader(datasets['toktok']['tfidf_svd']['valid'], batch_size=BATCH_SIZE),\n",
    "        'test': DataLoader(datasets['toktok']['tfidf_svd']['test'], batch_size=BATCH_SIZE),\n",
    "    },\n",
    "}}\n",
    "\n",
    "# Show shapes and types\n",
    "print('Training examples:  ', len(dataloaders['toktok']['bow']['train'].dataset))\n",
    "print('Validation examples:', len(dataloaders['toktok']['bow']['valid'].dataset))\n",
    "print('Test examples:      ', len(dataloaders['toktok']['bow']['test'].dataset))\n",
    "print()\n",
    "print('Training batches:  ', len(dataloaders['toktok']['bow']['train']))\n",
    "print('Validation batches:', len(dataloaders['toktok']['bow']['valid']))\n",
    "print('Test batches:      ', len(dataloaders['toktok']['bow']['test']))\n",
    "print()\n",
    "X, y = next(iter(dataloaders['toktok']['bow']['train']))\n",
    "print(f'Shape of X: {X.shape} {X.dtype}')\n",
    "print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "print()\n",
    "X, y = next(iter(dataloaders['toktok']['bow_svd']['train']))\n",
    "print(f'Shape of X: {X.shape} {X.dtype}')\n",
    "print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "print()\n",
    "display(X[0])\n",
    "display(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51485a-e469-4dba-8e1f-e49f62abde40",
   "metadata": {},
   "source": [
    "## Token vectorizers\n",
    "### Word2Vec\n",
    "#### Train from the ground up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb38de3-5e15-401c-8e73-30b1e2662e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary shape:\n",
      "(10611, 100)\n",
      "\n",
      "Most frequent words:\n",
      "\"\n",
      "@user\n",
      "'\n",
      ",\n",
      "!\n",
      ".\n",
      ":\n",
      "...\n",
      "?\n",
      "may\n",
      "tomorrow\n",
      "go\n",
      ")\n",
      "day\n",
      "-\n",
      "get\n",
      "see\n",
      "like\n",
      "(\n",
      ";\n",
      "\n",
      "CPU times: user 1.8 ms, sys: 1.89 ms, total: 3.69 ms\n",
      "Wall time: 4.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_size = 100\n",
    "file = WORKING_PATH + 'word2vec_' + str(vector_size) + '.gensim'\n",
    "saving = True\n",
    "\n",
    "# Load model if it already exists\n",
    "if os.path.isfile(file):\n",
    "    word2vec = gensim.models.KeyedVectors.load(file, mmap='r')\n",
    "\n",
    "else:\n",
    "    # Initialize tokenizer wiht corpus in it\n",
    "    tokenizer = sentiment_utils.Tokenizer(dataset['train']['text']\n",
    "                                          + dataset['test']['text']\n",
    "                                          + dataset['validation']['text'])\n",
    "\n",
    "    # Train the model\n",
    "    word2vec = gensim.models.Word2Vec(\n",
    "        sentences=tokenizer, vector_size=vector_size, window=5, min_count=5, sg=1, hs=0, negative=5,\n",
    "        workers=7, epochs=5, seed=RANDOM_STATE,\n",
    "    )\n",
    "    \n",
    "    # Use the word vectors only\n",
    "    word2vec = word2vec.wv\n",
    "\n",
    "    # Save the model word vectors\n",
    "    if saving:\n",
    "        word2vec.save(file)\n",
    "\n",
    "# Print vocabulary shape\n",
    "print('Vocabulary shape:')\n",
    "print((len(word2vec.index_to_key), vector_size))\n",
    "print()\n",
    "\n",
    "# Print most frequent words\n",
    "print('Most frequent words:')\n",
    "for word in word2vec.index_to_key[:20]:\n",
    "    print(word)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20dec7-403d-4e23-b2eb-2ebda1ca5984",
   "metadata": {},
   "source": [
    "Show examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4a724d-eae0-4972-9e91-362ce7271af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vector example:\n",
      "[-6.7988336e-03 -7.7007711e-03 -6.7419447e-03  7.7721477e-03\n",
      " -9.1446610e-03 -6.6873073e-03 -6.6153635e-03 -2.2669220e-03\n",
      "  5.0509833e-03  5.8403742e-03  6.4396439e-03  8.6656129e-03\n",
      " -8.7526087e-03 -9.2006801e-04 -1.6529012e-03 -6.5322830e-03\n",
      " -3.4659612e-03 -1.9954813e-03  8.2546510e-03  1.9973540e-03\n",
      " -9.0243109e-03  4.0886807e-03 -5.3359149e-04 -2.5054060e-03\n",
      " -6.9734524e-03 -4.2239283e-03 -1.2363232e-03  1.5906275e-03\n",
      "  1.5835894e-03  6.6484306e-03 -1.8646896e-03  9.8702870e-03\n",
      "  9.3534179e-03 -8.1601581e-03 -3.8998926e-03 -6.2233713e-03\n",
      " -3.3651828e-04  2.3092914e-03 -2.8936565e-03 -3.0549956e-03\n",
      "  3.3477665e-04 -2.8081452e-03 -7.9259863e-03 -8.3585903e-03\n",
      "  6.7217945e-04  9.0850675e-03 -8.8485815e-03 -3.2784594e-03\n",
      " -1.6568815e-03  7.9573207e-03  2.2853673e-03 -1.6162921e-03\n",
      " -7.9821423e-03  3.6615168e-03 -2.7477740e-06  2.6824963e-03\n",
      " -9.2297187e-03 -8.0831572e-03  2.4737692e-03  4.3313741e-03\n",
      " -6.3958620e-03 -1.2299264e-03  1.1683321e-03  9.0518082e-03\n",
      "  3.1548619e-04  3.0346382e-03  4.2372416e-03  6.7232894e-03\n",
      " -3.3694482e-03  1.9274366e-03  5.5399071e-03  2.0930672e-03\n",
      " -1.5624798e-03  5.8541680e-03 -6.7653833e-03  5.1936209e-03\n",
      "  2.0783448e-03  2.3969626e-03 -1.6580462e-04  6.9747807e-04\n",
      " -5.3472710e-03  1.8660760e-03 -6.5726280e-04  5.8715190e-03\n",
      "  7.2001112e-03  1.9464636e-03 -7.0486926e-03 -2.4714721e-03\n",
      "  8.2157822e-03  4.9938383e-03 -9.0842601e-03 -7.7735009e-03\n",
      "  2.8241635e-03 -4.6629561e-03 -2.8908777e-03  1.8842184e-03\n",
      "  5.3190198e-03  5.8819582e-03 -2.7071154e-03  4.0055071e-03]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# Print the vector example\n",
    "print('A vector example:')\n",
    "print(word2vec['@user'])\n",
    "print(word2vec['@user'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6bb43-a899-4c87-bdbb-13b4cc7c53bc",
   "metadata": {},
   "source": [
    "### fastText\n",
    "#### Train from the ground up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7469688a-3d07-4084-a22f-cd8123778a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary shape:\n",
      "(10611, 100)\n",
      "\n",
      "Most frequent words:\n",
      "\"\n",
      "@user\n",
      "'\n",
      ",\n",
      "!\n",
      ".\n",
      ":\n",
      "...\n",
      "?\n",
      "may\n",
      "tomorrow\n",
      "go\n",
      ")\n",
      "day\n",
      "-\n",
      "get\n",
      "see\n",
      "like\n",
      "(\n",
      ";\n",
      "\n",
      "CPU times: user 386 ms, sys: 311 ms, total: 697 ms\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_size = 100\n",
    "file = WORKING_PATH + 'fasttext_' + str(vector_size) + '.gensim'\n",
    "saving = True\n",
    "\n",
    "# Load model if it already exists\n",
    "if os.path.isfile(file):\n",
    "    fasttext = gensim.models.fasttext.FastTextKeyedVectors.load(file, mmap='r')\n",
    "\n",
    "else:\n",
    "    # Initialize tokenizer wiht corpus in it\n",
    "    tokenizer = sentiment_utils.Tokenizer(dataset['train']['text']\n",
    "                                          + dataset['test']['text']\n",
    "                                          + dataset['validation']['text'])\n",
    "\n",
    "    # Train the model\n",
    "    fasttext = gensim.models.FastText(\n",
    "        sentences=tokenizer, vector_size=vector_size, window=5, min_count=5, sg=1, hs=0, negative=5,\n",
    "        workers=7, epochs=5, seed=RANDOM_STATE,\n",
    "    )\n",
    "    \n",
    "    # Use the word vectors only\n",
    "    fasttext = fasttext.wv\n",
    "\n",
    "    # Save the model word vectors\n",
    "    if saving:\n",
    "        fasttext.save(file)\n",
    "\n",
    "# Print vocabulary shape\n",
    "print('Vocabulary shape:')\n",
    "print((len(fasttext.index_to_key), vector_size))\n",
    "print()\n",
    "\n",
    "# Print most frequent words\n",
    "print('Most frequent words:')\n",
    "for word in fasttext.index_to_key[:20]:\n",
    "    print(word)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed2c73-7434-47f7-8091-c71a15bec868",
   "metadata": {},
   "source": [
    "Show examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09f0bd21-0d25-44c9-9f5c-54adb58eed47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vector example:\n",
      "[-4.87358047e-04  4.51807398e-04  8.77588638e-04 -3.32686584e-04\n",
      " -1.02142920e-03 -5.65615657e-04 -1.85830169e-03 -1.64301752e-03\n",
      " -3.25506413e-03  4.57338197e-03  1.27422193e-03  3.48202884e-03\n",
      "  1.94513152e-04  1.38777623e-05  2.34347157e-04  1.86236299e-04\n",
      "  1.52681104e-03  1.45538780e-03 -2.91749515e-04 -8.49718112e-04\n",
      " -1.08485331e-03  7.60952767e-04  2.18979130e-03  1.52153475e-03\n",
      " -8.63333640e-04 -1.12725690e-03 -4.13653994e-04 -9.69837129e-04\n",
      " -3.50951846e-03  2.00337311e-03  2.72217090e-03  9.62128979e-04\n",
      " -9.16386663e-04 -2.23301514e-03 -9.92241781e-04 -4.96376480e-04\n",
      " -2.19261716e-03  4.06168081e-04 -2.76850234e-03 -2.22463836e-03\n",
      "  1.32712605e-03 -9.71838774e-04 -3.71666916e-04 -3.45141103e-04\n",
      "  2.19832268e-03 -4.77933296e-04 -1.50938821e-03 -8.66060960e-04\n",
      "  1.31140207e-03 -1.85101863e-03  1.01888634e-03  2.18549496e-04\n",
      " -1.96930929e-03 -6.17635378e-04  2.47252802e-03 -8.30107136e-04\n",
      "  1.03148588e-04  3.78433871e-03 -1.67751324e-03  8.75202590e-04\n",
      " -7.45509460e-04 -7.74183136e-04 -1.29649055e-03 -3.31599877e-04\n",
      " -3.02510476e-03  2.44991155e-03 -1.57515251e-03  1.12388586e-03\n",
      " -2.91600311e-03 -4.86238365e-04  1.43003138e-03 -7.21334654e-04\n",
      "  2.63229012e-03  3.56963661e-04  1.17806520e-03 -8.68825533e-04\n",
      " -6.35157165e-04  8.25674972e-04  1.32847368e-03  2.76971678e-03\n",
      " -6.66425563e-04  4.56986832e-04  2.44077365e-03 -1.48916186e-03\n",
      "  2.13712151e-03 -8.01523274e-04 -8.83655041e-04 -4.45649057e-04\n",
      " -1.41387770e-03  1.21046486e-03 -1.74477522e-03  3.50933144e-04\n",
      " -9.27234869e-05 -1.16335781e-04 -2.03814032e-03  1.53253477e-05\n",
      "  8.33417071e-05  2.39008456e-03 -1.16614625e-04  1.16813590e-03]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# Print the vector example\n",
    "print('A vector example:')\n",
    "print(fasttext['@user'])\n",
    "print(fasttext['@user'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f7c57-6a5b-45cb-acb7-2aca597d738e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computational graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b31da21-e7a5-4f43-bc60-e65c5bc73086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f84d80f9-8a68-4b06-938f-73b835a5509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For \"toktok_bow_logreg\" model:\n",
      "- all params:       [150000, 3]   total: 150003\n",
      "- trainable params: [150000, 3]   total: 150003\n",
      "- LogRegModel(\n",
      "  (linear): Linear(in_features=50000, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "For \"toktok_bow_svd_logreg\" model:\n",
      "- all params:       [300, 3]   total: 303\n",
      "- trainable params: [300, 3]   total: 303\n",
      "- LogRegModel(\n",
      "  (linear): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LogRegModel(nn.Module):\n",
    "    \"\"\"Logistic Regression model\"\"\"\n",
    "    def __init__(self, n_neurons):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_neurons, CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "models['toktok_bow_logreg'] = LogRegModel(VOCAB_SIZE)\n",
    "models['toktok_hbow_logreg'] = LogRegModel(VOCAB_SIZE)\n",
    "models['toktok_tfidf_logreg'] = LogRegModel(VOCAB_SIZE)\n",
    "models['toktok_bow_svd_logreg'] = LogRegModel(SVD_SIZE)\n",
    "models['toktok_hbow_svd_logreg'] = LogRegModel(SVD_SIZE)\n",
    "models['toktok_tfidf_svd_logreg'] = LogRegModel(SVD_SIZE)\n",
    "\n",
    "# Print model info\n",
    "model = 'toktok_bow_logreg'\n",
    "params = [p.numel() for p in models[model].parameters()]\n",
    "print(f'For \"{model}\" model:')\n",
    "print('- all params:      ', params, '  total:', sum(params))\n",
    "params = [p.numel() for p in models[model].parameters() if p.requires_grad]\n",
    "print('- trainable params:', params, '  total:', sum(params))\n",
    "print('-', models[model])\n",
    "print()\n",
    "model = 'toktok_bow_svd_logreg'\n",
    "params = [p.numel() for p in models[model].parameters()]\n",
    "print(f'For \"{model}\" model:')\n",
    "print('- all params:      ', params, '  total:', sum(params))\n",
    "params = [p.numel() for p in models[model].parameters() if p.requires_grad]\n",
    "print('- trainable params:', params, '  total:', sum(params))\n",
    "print('-', models[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40b4423d-17c0-4a89-8dfb-40723ef26f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For \"toktok_bow_dense2\" model:\n",
      "- all params:       [5000000, 100, 300, 3]   total: 5000403\n",
      "- trainable params: [5000000, 100, 300, 3]   total: 5000403\n",
      "- Dense2Model(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=50000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "For \"toktok_bow_svd_dense2\" model:\n",
      "- all params:       [10000, 100, 300, 3]   total: 10403\n",
      "- trainable params: [10000, 100, 300, 3]   total: 10403\n",
      "- Dense2Model(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Dense2Model(nn.Module):\n",
    "    \"\"\"Dense model with 2 fully connected layers\"\"\"\n",
    "    def __init__(self, n_neurons):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(n_neurons[0], n_neurons[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons[1], CLASSES),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "models['toktok_bow_dense2'] = Dense2Model((VOCAB_SIZE, SVD_SIZE))\n",
    "models['toktok_hbow_dense2'] = Dense2Model((VOCAB_SIZE, SVD_SIZE))\n",
    "models['toktok_tfidf_dense2'] = Dense2Model((VOCAB_SIZE, SVD_SIZE))\n",
    "models['toktok_bow_svd_dense2'] = Dense2Model((SVD_SIZE, SVD_SIZE))\n",
    "models['toktok_hbow_svd_dense2'] = Dense2Model((SVD_SIZE, SVD_SIZE))\n",
    "models['toktok_tfidf_svd_dense2'] = Dense2Model((SVD_SIZE, SVD_SIZE))\n",
    "\n",
    "# Print model info\n",
    "model = 'toktok_bow_dense2'\n",
    "params = [p.numel() for p in models[model].parameters()]\n",
    "print(f'For \"{model}\" model:')\n",
    "print('- all params:      ', params, '  total:', sum(params))\n",
    "params = [p.numel() for p in models[model].parameters() if p.requires_grad]\n",
    "print('- trainable params:', params, '  total:', sum(params))\n",
    "print('-', models[model])\n",
    "print()\n",
    "model = 'toktok_bow_svd_dense2'\n",
    "params = [p.numel() for p in models[model].parameters()]\n",
    "print(f'For \"{model}\" model:')\n",
    "print('- all params:      ', params, '  total:', sum(params))\n",
    "params = [p.numel() for p in models[model].parameters() if p.requires_grad]\n",
    "print('- trainable params:', params, '  total:', sum(params))\n",
    "print('-', models[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850577d-d08e-480f-aca1-d5bee071de72",
   "metadata": {},
   "source": [
    "## Range test for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f410a07b-66a9-4a78-b8cc-31dddffda1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toktok_bow_logreg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213893ebc24e47feab02151ded39e755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Range test for LR\u001b[39;00m\n\u001b[1;32m     16\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m LRFinder(model, optimizer, loss_fn)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mlr_finder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoktok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoktok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mend_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Inspect the loss-LR graph\u001b[39;00m\n\u001b[1;32m     23\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch_lr_finder/lr_finder.py:317\u001b[0m, in \u001b[0;36mLRFinder.range_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`val_loader` has unsupported type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected types are `torch.utils.data.DataLoader`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor child of `ValDataLoaderIter`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(val_loader))\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_iter)):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# Train on batch and retrieve loss\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking_transfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking_transfer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    323\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\n\u001b[1;32m    324\u001b[0m             val_iter, non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch_lr_finder/lr_finder.py:377\u001b[0m, in \u001b[0;36mLRFinder._train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    372\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_to_device(\n\u001b[1;32m    373\u001b[0m     inputs, labels, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    374\u001b[0m )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Loss should be averaged in each step\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m, in \u001b[0;36mLogRegModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 8\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ml-service/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "if DO_LR_RANGE_TEST:\n",
    "    start_lr = 1e-4\n",
    "    end_lr = 1e1\n",
    "    num_iter = 50\n",
    "\n",
    "    # Loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(name)\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=start_lr)\n",
    "\n",
    "        # Range test for LR\n",
    "        lr_finder = LRFinder(model, optimizer, loss_fn)\n",
    "        lr_finder.range_test(train_loader=dataloaders['toktok']['bow']['train'],\n",
    "                             val_loader=dataloaders['toktok']['bow']['valid'],\n",
    "                             end_lr=end_lr,\n",
    "                             num_iter=num_iter)\n",
    "        \n",
    "        # Inspect the loss-LR graph\n",
    "        lr_finder.plot()\n",
    "        \n",
    "        # Reset the model and optimizer to their initial state\n",
    "        lr_finder.reset()\n",
    "else:\n",
    "    lrs = {\n",
    "        'logreg': 1e-1,\n",
    "        'dense3': 6e-1,\n",
    "        'conv3': 1e-1,\n",
    "        'conv5': 4e-1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46bd77-841a-4888-a9e9-54791767c181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
